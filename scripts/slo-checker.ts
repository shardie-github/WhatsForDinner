#!/usr/bin/env tsx

/**
 * SLO (Service Level Objective) Checker
 * 
 * This script monitors and validates SLOs:
 * - API success rate (>= 99.9% 7-day)
 * - p95 latency for critical endpoints (‚â§ 400 ms Preview, ‚â§ 300 ms Prod)
 * - DB error rate (< 0.1%)
 */

import { createClient } from '@supabase/supabase-js';
import { writeFileSync, existsSync } from 'fs';
import { join } from 'path';

interface SLOConfig {
  api_success_rate_threshold: number; // 99.9%
  api_latency_p95_threshold_preview: number; // 400ms
  api_latency_p95_threshold_production: number; // 300ms
  db_error_rate_threshold: number; // 0.1%
  evaluation_window_hours: number; // 24 hours
  error_budget_threshold: number; // 5% error budget remaining
}

interface SLOMetrics {
  api_success_rate: number;
  api_latency_p95: number;
  db_error_rate: number;
  total_requests: number;
  failed_requests: number;
  db_errors: number;
  evaluation_period: string;
}

interface SLOReport {
  timestamp: string;
  environment: string;
  overall_status: 'pass' | 'fail' | 'warning';
  metrics: SLOMetrics;
  violations: string[];
  recommendations: string[];
  error_budget_remaining: number;
}

const DEFAULT_CONFIG: SLOConfig = {
  api_success_rate_threshold: 99.9,
  api_latency_p95_threshold_preview: 400,
  api_latency_p95_threshold_production: 300,
  db_error_rate_threshold: 0.1,
  evaluation_window_hours: 24,
  error_budget_threshold: 5.0
};

class SLOChecker {
  private supabase: any;
  private config: SLOConfig;
  private environment: string;

  constructor(
    supabaseUrl: string, 
    supabaseKey: string, 
    environment: string = 'production',
    config: Partial<SLOConfig> = {}
  ) {
    this.supabase = createClient(supabaseUrl, supabaseKey);
    this.config = { ...DEFAULT_CONFIG, ...config };
    this.environment = environment;
  }

  /**
   * Collect API metrics from logs
   */
  async collectAPIMetrics(): Promise<Partial<SLOMetrics>> {
    console.log('üìä Collecting API metrics...');
    
    try {
      // In a real implementation, this would query actual log data
      // For now, we'll simulate with some test data
      const endTime = new Date();
      const startTime = new Date(endTime.getTime() - (this.config.evaluation_window_hours * 60 * 60 * 1000));
      
      // Simulate API metrics based on environment
      const baseSuccessRate = this.environment === 'production' ? 99.95 : 99.5;
      const baseLatency = this.environment === 'production' ? 250 : 350;
      const baseErrorRate = this.environment === 'production' ? 0.05 : 0.2;
      
      // Add some realistic variance
      const successRate = baseSuccessRate + (Math.random() - 0.5) * 0.1;
      const latency = baseLatency + (Math.random() - 0.5) * 100;
      const errorRate = Math.max(0, baseErrorRate + (Math.random() - 0.5) * 0.1);
      
      const totalRequests = Math.floor(10000 + Math.random() * 5000);
      const failedRequests = Math.floor(totalRequests * (100 - successRate) / 100);
      const dbErrors = Math.floor(totalRequests * errorRate / 100);
      
      return {
        api_success_rate: Math.round(successRate * 100) / 100,
        api_latency_p95: Math.round(latency),
        db_error_rate: Math.round(errorRate * 100) / 100,
        total_requests: totalRequests,
        failed_requests: failedRequests,
        db_errors: dbErrors,
        evaluation_period: `${startTime.toISOString()} to ${endTime.toISOString()}`
      };
      
    } catch (error) {
      console.error('‚ùå Failed to collect API metrics:', error);
      throw error;
    }
  }

  /**
   * Collect database metrics
   */
  async collectDBMetrics(): Promise<Partial<SLOMetrics>> {
    console.log('üóÑÔ∏è Collecting database metrics...');
    
    try {
      // Query database for error rates and performance
      const dbMetricsSQL = `
        SELECT 
          COUNT(*) as total_queries,
          COUNT(CASE WHEN error_message IS NOT NULL THEN 1 END) as error_count,
          PERCENTILE_CONT(0.95) WITHIN GROUP (ORDER BY execution_time_ms) as p95_latency
        FROM query_logs 
        WHERE created_at >= NOW() - INTERVAL '${this.config.evaluation_window_hours} hours'
      `;

      // For simulation, return mock data
      const totalQueries = Math.floor(50000 + Math.random() * 10000);
      const errorCount = Math.floor(totalQueries * (this.config.db_error_rate_threshold / 100) * (0.5 + Math.random()));
      const p95Latency = 50 + Math.random() * 20;

      return {
        total_requests: totalQueries,
        db_errors: errorCount,
        api_latency_p95: p95Latency
      };
      
    } catch (error) {
      console.error('‚ùå Failed to collect DB metrics:', error);
      // Return safe defaults if DB query fails
      return {
        total_requests: 0,
        db_errors: 0,
        api_latency_p95: 0
      };
    }
  }

  /**
   * Evaluate SLOs against collected metrics
   */
  evaluateSLOs(metrics: SLOMetrics): { violations: string[]; recommendations: string[]; error_budget_remaining: number } {
    const violations: string[] = [];
    const recommendations: string[] = [];
    
    // Check API success rate
    if (metrics.api_success_rate < this.config.api_success_rate_threshold) {
      violations.push(`API success rate ${metrics.api_success_rate}% below threshold ${this.config.api_success_rate_threshold}%`);
      recommendations.push('Investigate API error patterns and improve error handling');
    }
    
    // Check API latency
    const latencyThreshold = this.environment === 'production' 
      ? this.config.api_latency_p95_threshold_production 
      : this.config.api_latency_p95_threshold_preview;
      
    if (metrics.api_latency_p95 > latencyThreshold) {
      violations.push(`API p95 latency ${metrics.api_latency_p95}ms exceeds threshold ${latencyThreshold}ms`);
      recommendations.push('Optimize API performance and consider caching strategies');
    }
    
    // Check database error rate
    if (metrics.db_error_rate > this.config.db_error_rate_threshold) {
      violations.push(`DB error rate ${metrics.db_error_rate}% exceeds threshold ${this.config.db_error_rate_threshold}%`);
      recommendations.push('Review database queries and connection handling');
    }
    
    // Calculate error budget remaining
    const errorBudgetUsed = (100 - metrics.api_success_rate) / (100 - this.config.api_success_rate_threshold);
    const errorBudgetRemaining = Math.max(0, 100 - (errorBudgetUsed * 100));
    
    if (errorBudgetRemaining < this.config.error_budget_threshold) {
      violations.push(`Error budget remaining ${errorBudgetRemaining.toFixed(2)}% below threshold ${this.config.error_budget_threshold}%`);
      recommendations.push('Consider reducing feature velocity or improving reliability');
    }
    
    return { violations, recommendations, error_budget_remaining: errorBudgetRemaining };
  }

  /**
   * Generate SLO report
   */
  generateSLOReport(metrics: SLOMetrics, evaluation: any): SLOReport {
    const overallStatus = evaluation.violations.length === 0 ? 'pass' : 
                         evaluation.violations.length <= 2 ? 'warning' : 'fail';
    
    return {
      timestamp: new Date().toISOString(),
      environment: this.environment,
      overall_status: overallStatus,
      metrics,
      violations: evaluation.violations,
      recommendations: evaluation.recommendations,
      error_budget_remaining: evaluation.error_budget_remaining
    };
  }

  /**
   * Save SLO report to file
   */
  async saveSLOReport(report: SLOReport): Promise<string> {
    const timestamp = new Date().toISOString().replace(/[:.]/g, '-');
    const filename = `slo-report-${this.environment}-${timestamp}.json`;
    const filepath = join(process.cwd(), 'REPORTS', filename);
    
    // Ensure REPORTS directory exists
    const { execSync } = await import('child_process');
    execSync('mkdir -p REPORTS', { stdio: 'inherit' });
    
    writeFileSync(filepath, JSON.stringify(report, null, 2));
    console.log(`üìÑ SLO report saved to: ${filepath}`);
    
    return filepath;
  }

  /**
   * Main SLO checking process
   */
  async execute(): Promise<SLOReport> {
    console.log(`üöÄ Starting SLO check for ${this.environment} environment...`);
    
    try {
      // Collect metrics
      const apiMetrics = await this.collectAPIMetrics();
      const dbMetrics = await this.collectDBMetrics();
      
      // Combine metrics
      const metrics: SLOMetrics = {
        api_success_rate: apiMetrics.api_success_rate || 0,
        api_latency_p95: apiMetrics.api_latency_p95 || 0,
        db_error_rate: apiMetrics.db_error_rate || 0,
        total_requests: apiMetrics.total_requests || 0,
        failed_requests: apiMetrics.failed_requests || 0,
        db_errors: dbMetrics.db_errors || 0,
        evaluation_period: apiMetrics.evaluation_period || ''
      };
      
      // Evaluate SLOs
      const evaluation = this.evaluateSLOs(metrics);
      
      // Generate report
      const report = this.generateSLOReport(metrics, evaluation);
      
      // Save report
      await this.saveSLOReport(report);
      
      // Log results
      console.log(`\nüìä SLO Check Results:`);
      console.log(`  Environment: ${this.environment}`);
      console.log(`  Status: ${report.overall_status.toUpperCase()}`);
      console.log(`  API Success Rate: ${metrics.api_success_rate}%`);
      console.log(`  API p95 Latency: ${metrics.api_latency_p95}ms`);
      console.log(`  DB Error Rate: ${metrics.db_error_rate}%`);
      console.log(`  Error Budget Remaining: ${evaluation.error_budget_remaining.toFixed(2)}%`);
      
      if (evaluation.violations.length > 0) {
        console.log(`\n‚ùå Violations:`);
        evaluation.violations.forEach(violation => console.log(`  - ${violation}`));
      }
      
      if (evaluation.recommendations.length > 0) {
        console.log(`\nüí° Recommendations:`);
        evaluation.recommendations.forEach(rec => console.log(`  - ${rec}`));
      }
      
      return report;
      
    } catch (error) {
      console.error('‚ùå SLO check failed:', error);
      throw error;
    }
  }
}

// CLI interface
async function main() {
  const args = process.argv.slice(2);
  const environment = args.find(arg => arg.startsWith('--env='))?.split('=')[1] || 'production';
  const isCheckMode = args.includes('--check');

  const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL;
  const supabaseKey = process.env.SUPABASE_SERVICE_ROLE_KEY;

  if (!supabaseUrl || !supabaseKey) {
    console.error('‚ùå Missing required environment variables:');
    console.error('  - NEXT_PUBLIC_SUPABASE_URL');
    console.error('  - SUPABASE_SERVICE_ROLE_KEY');
    process.exit(1);
  }

  const checker = new SLOChecker(supabaseUrl, supabaseKey, environment);

  try {
    const report = await checker.execute();
    
    if (isCheckMode) {
      if (report.overall_status === 'fail') {
        console.log('\n‚ùå SLO check failed - see report for details');
        process.exit(1);
      } else if (report.overall_status === 'warning') {
        console.log('\n‚ö†Ô∏è SLO check passed with warnings');
        process.exit(0);
      } else {
        console.log('\n‚úÖ SLO check passed');
        process.exit(0);
      }
    }
    
  } catch (error) {
    console.error('Fatal error during SLO check:', error);
    process.exit(1);
  }
}

// Run if called directly
if (require.main === module) {
  main().catch(error => {
    console.error('Fatal error:', error);
    process.exit(1);
  });
}

export { SLOChecker, SLOReport, SLOMetrics };
